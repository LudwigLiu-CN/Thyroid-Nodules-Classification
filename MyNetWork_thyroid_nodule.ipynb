{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import resnet\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage import feature as ft\n",
    "from skimage import transform\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "import FinalNetwork \n",
    "import MyNetWork \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureselected(img):\n",
    "    hog_features = ft.hog(img,  # input image\n",
    "                  orientations=8,  # number of bins\n",
    "                  pixels_per_cell=(20,20), # pixel per cell\n",
    "                  cells_per_block=(2,2), # cells per blcok\n",
    "                  block_norm = 'L2-Hys', #  block norm : str {‘L1’, ‘L1-sqrt’, ‘L2’, ‘L2-Hys’}\n",
    "                  transform_sqrt = True, # power law compression (also known as gamma correction)\n",
    "                  feature_vector=True, # flatten the final vectors\n",
    "                  visualize=False) # return HOG map\n",
    "    \n",
    "    temp = img.reshape(128,128)\n",
    "    \n",
    "    lbp_features = ft.local_binary_pattern(temp,  # input image\n",
    "                                   P=8,  # Number of circularly symmetric neighbour set points\n",
    "                                   R=1.0, # Radius of circle\n",
    "                                   method='default') # {'default', 'ror', 'uniform', 'var'}\n",
    "    \n",
    "    haar_features = ft.haar_like_feature(temp,  # input image\n",
    "                                0,  # Row-coordinate of top left corner of the detection window.\n",
    "                                0,  # Column-coordinate of top left corner of the detection window.\n",
    "                                5,  # Width of the detection window.\n",
    "                                5,  # Height of the detection window.\n",
    "                                feature_type=None # The type of feature to consider:\n",
    "                                )\n",
    "    \n",
    "    _lbp = lbp_features.flatten()\n",
    "    \n",
    "    train = np.concatenate((hog_features, _lbp, haar_features),axis=0)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 17472)\n",
      "(1022, 128, 128, 1)\n",
      "(1022, 2)\n",
      "(1022, 1, 17472, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "Input = np.load('Data/final_data.npz')\n",
    "\n",
    "data = Input[\"data\"]\n",
    "label = Input[\"label\"]\n",
    "\n",
    "feature = []\n",
    "for i in range(data.shape[0]):\n",
    "    feature.append(featureselected(data[i]))\n",
    "feature = np.array(feature)\n",
    "print (feature.shape)\n",
    "feature.resize(feature.shape[0],1, feature.shape[1],1)\n",
    "\n",
    "print (data.shape)\n",
    "print (label.shape)\n",
    "print (feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 1, 17472, 1)\n"
     ]
    }
   ],
   "source": [
    "def unison_shuffled_copies(a, b, c, rl):\n",
    "    assert len(a) == len(b)\n",
    "    assert len(a) == len(c)\n",
    "    r=list(range(len(a)))\n",
    "#     random.shuffle(r,lambda:rl)\n",
    "    random.shuffle(r,lambda:rl)\n",
    "    p=np.array(r)\n",
    "    #p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p]\n",
    "\n",
    "data,label,feature=unison_shuffled_copies(data,label,feature,0.5)\n",
    "\n",
    "print(feature.shape)\n",
    "\n",
    "splitpoint = int(round(len(data) * 0.8))\n",
    "(x_train_arr, x_test_arr) = (data[0:splitpoint], data[splitpoint:])\n",
    "(f_train_arr, f_test_arr) = (feature[0:splitpoint], feature[splitpoint:])\n",
    "(y_train_arr, y_test_arr) = (label[0:splitpoint], label[splitpoint:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (818, 128, 128, 1))\n",
      "('y_train_shape:', (818, 2))\n",
      "(818, 'train samples')\n",
      "(204, 'test samples')\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train_arr.shape)\n",
    "print('y_train_shape:', y_train_arr.shape)\n",
    "print(x_train_arr.shape[0], 'train samples')\n",
    "print(x_test_arr.shape[0], 'test samples')\n",
    "\n",
    "num_0 = 0\n",
    "for i in range(len(x_test_arr)):\n",
    "    if y_test_arr[i][1]==1:\n",
    "        num_0+=1\n",
    "print(num_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def TPR(y_true, y_pred):\n",
    "    TP = K.sum(y_pred*y_true)\n",
    "    P = K.sum(y_true)\n",
    "    return TP/P\n",
    "\n",
    "def TNR(y_true, y_pred):\n",
    "    TN = K.sum((1-y_true)*(1-y_pred))\n",
    "    N = K.sum(1-y_true)\n",
    "    return TN/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 62, 62, 16)   160         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 62, 62, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 31, 31, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 29, 29, 32)   4640        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 29, 29, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 32)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 12, 12, 64)   18496       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 12, 12, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 9216)         0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           460850      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 50)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            306         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_interpolation_1 (Bilin (None, 128, 128, 1)  0           input_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 124, 124, 20) 520         bilinear_interpolation_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 62, 62, 64)   62784       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 62, 62, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 62, 62, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 31, 31, 64)   0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 31, 31, 64)   4160        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 31, 31, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 31, 31, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 31, 31, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 31, 31, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 31, 31, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 31, 31, 256)  16640       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 31, 31, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 31, 31, 256)  0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 31, 31, 256)  1024        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 31, 31, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 31, 31, 64)   16448       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 31, 31, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 31, 31, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 31, 31, 64)   36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 31, 31, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 31, 31, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 31, 31, 256)  16640       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 31, 31, 256)  0           add_1[0][0]                      \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 31, 31, 256)  1024        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 31, 31, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 31, 31, 64)   16448       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 31, 31, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 31, 31, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 31, 31, 64)   36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 31, 31, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 31, 31, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 31, 31, 256)  16640       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 31, 31, 256)  0           add_2[0][0]                      \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 31, 31, 256)  1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 31, 31, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 128)  32896       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 512)  131584      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 512)  0           conv2d_21[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 512)  2048        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 512)  0           add_4[0][0]                      \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 512)  2048        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 512)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 128)  65664       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 128)  147584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 512)  66048       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 512)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 512)  2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 512)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 128)  65664       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 128)  512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 128)  147584      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 128)  512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 512)  66048       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 512)  0           add_6[0][0]                      \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 512)  2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 512)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 256)    131328      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 256)    1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 256)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 1024)   525312      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 1024)   263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 1024)   0           conv2d_34[0][0]                  \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 1024)   4096        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 256)    262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 256)    590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 256)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 1024)   263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 1024)   0           add_8[0][0]                      \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 1024)   4096        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 256)    262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 256)    1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 256)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 256)    590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 256)    1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 256)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 1024)   263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 1024)   0           add_9[0][0]                      \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 1024)   4096        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 256)    262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 256)    1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 256)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 256)    590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 256)    1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 256)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 1024)   263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 1024)   0           add_10[0][0]                     \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 1024)   4096        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 256)    262400      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 256)    1024        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 256)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 256)    590080      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 256)    1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 256)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 1024)   263168      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 1024)   0           add_11[0][0]                     \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 1024)   4096        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 256)    262400      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 256)    1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 256)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 256)    590080      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 256)    1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 256)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 1024)   263168      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 1024)   0           add_12[0][0]                     \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 1024)   4096        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 1024)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 512)    524800      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 512)    2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 512)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 512)    2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 4, 4, 2048)   2099200     add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 4, 4, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 2048)   0           conv2d_53[0][0]                  \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 2048)   8192        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 2048)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 4, 4, 512)    1049088     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 512)    2048        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 512)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 4, 4, 512)    2359808     activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 512)    2048        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 512)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 4, 4, 2048)   1050624     activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 2048)   0           add_14[0][0]                     \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 2048)   8192        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 4, 4, 2048)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 4, 4, 512)    1049088     activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 17472, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 512)    2048        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 8736, 1)   0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 4, 4, 512)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 1, 8734, 16)  64          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 4, 4, 512)    2359808     activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1, 8734, 16)  64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 512)    2048        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 8734, 16)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 4, 4, 512)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 4367, 16)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 4, 4, 2048)   1050624     activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 1, 4365, 32)  1568        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 2048)   0           add_15[0][0]                     \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 4365, 32)  128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 2048)   8192        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 4365, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 4, 4, 2048)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 2182, 32)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 2048)   0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 32)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2048)         0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32)           0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2080)         0           flatten_3[0][0]                  \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            4162        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 24,116,622\n",
      "Trainable params: 24,071,086\n",
      "Non-trainable params: 45,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "#lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
    "csv_logger = CSVLogger('Test.csv')\n",
    "\n",
    "batch_size = 64\n",
    "nb_classes = 2\n",
    "nb_epoch = 200\n",
    "Mysgd = keras.optimizers.SGD(lr=0.01)\n",
    "MyAdam = keras.optimizers.Adam(lr=0.1)\n",
    "\n",
    "model =  FinalNetwork.NetBuilder.finalNet(input_shape = (128, 128, 1), feature_shape = (1,17472, 1), num_outputs = nb_classes, sampling_size = (128, 128))\n",
    "#model = resnet.ResnetBuilder.build_resnet_50((1, 128, 128), nb_classes)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(818, 1, 17472, 1)\n",
      "(818, 128, 128, 1)\n",
      "(818, 2)\n",
      "=================\n",
      "(204, 128, 128, 1)\n",
      "(204, 1, 17472, 1)\n",
      "(204, 2)\n"
     ]
    }
   ],
   "source": [
    "print (f_train_arr.shape)\n",
    "print (x_train_arr.shape)\n",
    "print (y_train_arr.shape)\n",
    "\n",
    "print ('=================')\n",
    "print (x_test_arr.shape)\n",
    "print (f_test_arr.shape)\n",
    "print (y_test_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(x_train_arr,f_train_arr,y_train_arr):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "    \n",
    "    \n",
    "    genX1 = datagen.flow(x_train_arr,y_train_arr, batch_size=batch_size)\n",
    "#    genX2 = datagen.flow(f_train_arr, batch_size=batch_size)\n",
    "#     while True:\n",
    "#         X1i = genX1.next()\n",
    "#         X2i = genX2 .next()\n",
    "#         print (X1i[0].shape)\n",
    "#         print (X2i.shape)\n",
    "#         print (X1i[1].shape)\n",
    "#         yield ([X1i[0], X2i ], X1i[1])\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        #X2i = genX2 .next()\n",
    "        features = []\n",
    "        for i in range(len(X1i[0])):\n",
    "            features.append(featureselected(X1i[0][i]).reshape(1, 17472, 1))\n",
    "        features = np.array(features)\n",
    "\n",
    "        yield ([X1i[0], features ], X1i[1])   \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "def testGenerator(x_test_arr,f_test_arr,y_test_arr):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    datagen = ImageDataGenerator(rotation_range=90, \n",
    "                                   width_shift_range=0.05, \n",
    "                                   height_shift_range=0.05,\n",
    "                                   zoom_range=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    genX1 = datagen.flow(x_test_arr,y_test_arr, seed=7, batch_size=batch_size)\n",
    "    genX2 = datagen.flow(f_test_arr, seed=7, batch_size=batch_size)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "\n",
    "        yield ([X1i[0], X2i ], X1i[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., verbose=1, validation_data=([array([[..., steps_per_epoch=12, epochs=200, callbacks=[<keras.ca..., max_queue_size=100, validation_steps=3)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 29s 2s/step - loss: 4.9400 - acc: 0.5612 - val_loss: 12.8635 - val_acc: 0.4461\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 5s 418ms/step - loss: 4.6888 - acc: 0.6024 - val_loss: 9.9726 - val_acc: 0.4461\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 4s 346ms/step - loss: 4.4719 - acc: 0.6012 - val_loss: 10.1307 - val_acc: 0.4265\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 4.2988 - acc: 0.6086 - val_loss: 6.2990 - val_acc: 0.4510\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 4.1039 - acc: 0.6325 - val_loss: 4.7653 - val_acc: 0.5098\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 4s 357ms/step - loss: 3.8726 - acc: 0.6592 - val_loss: 6.5909 - val_acc: 0.4363\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 3.7136 - acc: 0.6622 - val_loss: 3.9181 - val_acc: 0.5735\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 4s 354ms/step - loss: 3.6198 - acc: 0.6236 - val_loss: 3.5989 - val_acc: 0.5539\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 4s 347ms/step - loss: 3.4470 - acc: 0.6314 - val_loss: 3.5594 - val_acc: 0.5098\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 4s 356ms/step - loss: 3.2863 - acc: 0.6670 - val_loss: 5.9066 - val_acc: 0.4461\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 4s 352ms/step - loss: 3.0831 - acc: 0.7152 - val_loss: 3.3537 - val_acc: 0.5049\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 4s 352ms/step - loss: 2.9803 - acc: 0.7088 - val_loss: 4.5150 - val_acc: 0.4510\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 2.8617 - acc: 0.6963 - val_loss: 3.2100 - val_acc: 0.4902\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 4s 355ms/step - loss: 2.7883 - acc: 0.6771 - val_loss: 6.6079 - val_acc: 0.4461\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 4s 355ms/step - loss: 2.6830 - acc: 0.6914 - val_loss: 2.7220 - val_acc: 0.6716\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 4s 355ms/step - loss: 2.5504 - acc: 0.7303 - val_loss: 2.8247 - val_acc: 0.5931\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 4s 353ms/step - loss: 2.4335 - acc: 0.7237 - val_loss: 2.9132 - val_acc: 0.5784\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 2.3511 - acc: 0.7123 - val_loss: 3.2393 - val_acc: 0.4853\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 2.2883 - acc: 0.7172 - val_loss: 2.6470 - val_acc: 0.5637\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 2.2096 - acc: 0.6876 - val_loss: 2.3231 - val_acc: 0.6373\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 4s 354ms/step - loss: 2.0883 - acc: 0.7312 - val_loss: 4.6385 - val_acc: 0.4608\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 4s 351ms/step - loss: 2.0634 - acc: 0.7088 - val_loss: 2.9742 - val_acc: 0.4657\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 4s 353ms/step - loss: 1.9942 - acc: 0.7081 - val_loss: 2.5513 - val_acc: 0.5637\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 4s 350ms/step - loss: 1.8831 - acc: 0.7629 - val_loss: 4.9236 - val_acc: 0.4559\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 4s 346ms/step - loss: 1.8640 - acc: 0.7205 - val_loss: 2.1940 - val_acc: 0.6225\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 5s 386ms/step - loss: 1.8118 - acc: 0.7273 - val_loss: 4.7148 - val_acc: 0.4706\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 5s 432ms/step - loss: 1.7330 - acc: 0.7552 - val_loss: 2.3972 - val_acc: 0.6127\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 5s 414ms/step - loss: 1.6428 - acc: 0.7945 - val_loss: 3.0181 - val_acc: 0.5637\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 5s 414ms/step - loss: 1.6814 - acc: 0.7185 - val_loss: 1.8227 - val_acc: 0.6618\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 5s 418ms/step - loss: 1.5832 - acc: 0.7721 - val_loss: 2.0679 - val_acc: 0.5882\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 1.5891 - acc: 0.7254 - val_loss: 5.9170 - val_acc: 0.4412\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 5s 440ms/step - loss: 1.5704 - acc: 0.7266 - val_loss: 3.5735 - val_acc: 0.4657\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 5s 439ms/step - loss: 1.5025 - acc: 0.7482 - val_loss: 4.6541 - val_acc: 0.4461\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 1.4630 - acc: 0.7655 - val_loss: 1.7698 - val_acc: 0.6176\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 5s 440ms/step - loss: 1.4666 - acc: 0.7273 - val_loss: 2.2203 - val_acc: 0.5588\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 5s 440ms/step - loss: 1.3926 - acc: 0.7658 - val_loss: 2.5517 - val_acc: 0.5686\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 5s 452ms/step - loss: 1.3693 - acc: 0.7573 - val_loss: 2.5415 - val_acc: 0.5196\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 5s 430ms/step - loss: 1.3196 - acc: 0.7517 - val_loss: 1.9571 - val_acc: 0.5686\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 5s 425ms/step - loss: 1.2600 - acc: 0.7919 - val_loss: 1.8780 - val_acc: 0.6373\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 6s 480ms/step - loss: 1.2676 - acc: 0.7865 - val_loss: 1.8938 - val_acc: 0.5882\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 5s 385ms/step - loss: 1.2111 - acc: 0.7880 - val_loss: 2.5074 - val_acc: 0.5882\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 5s 422ms/step - loss: 1.1684 - acc: 0.8252 - val_loss: 2.3853 - val_acc: 0.6176\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 5s 450ms/step - loss: 1.1697 - acc: 0.8148 - val_loss: 1.7846 - val_acc: 0.6569\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 5s 426ms/step - loss: 1.1474 - acc: 0.8415 - val_loss: 1.6166 - val_acc: 0.6912\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 5s 441ms/step - loss: 1.1240 - acc: 0.8506 - val_loss: 1.4040 - val_acc: 0.7304\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 1.1382 - acc: 0.8362 - val_loss: 1.3761 - val_acc: 0.7402\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 5s 421ms/step - loss: 1.1425 - acc: 0.8183 - val_loss: 1.2588 - val_acc: 0.7647\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 5s 420ms/step - loss: 1.0994 - acc: 0.8572 - val_loss: 1.1965 - val_acc: 0.7794\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 5s 424ms/step - loss: 1.1197 - acc: 0.8470 - val_loss: 1.2104 - val_acc: 0.7794\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 5s 420ms/step - loss: 1.0893 - acc: 0.8558 - val_loss: 1.2090 - val_acc: 0.7892\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 5s 425ms/step - loss: 1.0965 - acc: 0.8349 - val_loss: 1.1591 - val_acc: 0.8039\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 5s 434ms/step - loss: 1.0614 - acc: 0.8620 - val_loss: 1.1940 - val_acc: 0.8039\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 1.0789 - acc: 0.8581 - val_loss: 1.1779 - val_acc: 0.7941\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 5s 414ms/step - loss: 1.0735 - acc: 0.8575 - val_loss: 1.2083 - val_acc: 0.7892\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 5s 424ms/step - loss: 1.0800 - acc: 0.8588 - val_loss: 1.1302 - val_acc: 0.8382\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 5s 421ms/step - loss: 1.0335 - acc: 0.8679 - val_loss: 1.1259 - val_acc: 0.8235\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 5s 423ms/step - loss: 1.0378 - acc: 0.8663 - val_loss: 1.1741 - val_acc: 0.8137\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 5s 424ms/step - loss: 1.0529 - acc: 0.8617 - val_loss: 1.1978 - val_acc: 0.8039\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 5s 419ms/step - loss: 1.0643 - acc: 0.8598 - val_loss: 1.1726 - val_acc: 0.7990\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 5s 416ms/step - loss: 1.0250 - acc: 0.8848 - val_loss: 1.1885 - val_acc: 0.7941\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 5s 426ms/step - loss: 1.0190 - acc: 0.8760 - val_loss: 1.1845 - val_acc: 0.7892\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 5s 423ms/step - loss: 1.0302 - acc: 0.8751 - val_loss: 1.1727 - val_acc: 0.7745\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 1.0344 - acc: 0.8620 - val_loss: 1.1503 - val_acc: 0.7843\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 1.0266 - acc: 0.8800 - val_loss: 1.1399 - val_acc: 0.7941\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 5s 419ms/step - loss: 1.0128 - acc: 0.8731 - val_loss: 1.1350 - val_acc: 0.8039\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 5s 433ms/step - loss: 1.0063 - acc: 0.8711 - val_loss: 1.1261 - val_acc: 0.8235\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 5s 432ms/step - loss: 1.0160 - acc: 0.8718 - val_loss: 1.1177 - val_acc: 0.8088\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 5s 420ms/step - loss: 1.0140 - acc: 0.8643 - val_loss: 1.1144 - val_acc: 0.8137\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 5s 426ms/step - loss: 0.9927 - acc: 0.8888 - val_loss: 1.1181 - val_acc: 0.8137\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 5s 419ms/step - loss: 0.9952 - acc: 0.8887 - val_loss: 1.1183 - val_acc: 0.8039\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 5s 421ms/step - loss: 1.0348 - acc: 0.8633 - val_loss: 1.1236 - val_acc: 0.8039\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 5s 414ms/step - loss: 0.9837 - acc: 0.8911 - val_loss: 1.1147 - val_acc: 0.8088\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 5s 431ms/step - loss: 0.9822 - acc: 0.8822 - val_loss: 1.1031 - val_acc: 0.8088\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 5s 430ms/step - loss: 0.9912 - acc: 0.8884 - val_loss: 1.0992 - val_acc: 0.8137\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 0.9792 - acc: 0.8989 - val_loss: 1.0976 - val_acc: 0.8137\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 5s 416ms/step - loss: 1.0039 - acc: 0.8783 - val_loss: 1.0972 - val_acc: 0.8137\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 5s 428ms/step - loss: 0.9801 - acc: 0.8868 - val_loss: 1.0973 - val_acc: 0.8235\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 0.9758 - acc: 0.9021 - val_loss: 1.1011 - val_acc: 0.8235\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.9713 - acc: 0.8971 - val_loss: 1.1082 - val_acc: 0.8235\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 5s 421ms/step - loss: 0.9834 - acc: 0.8871 - val_loss: 1.1110 - val_acc: 0.8186\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 5s 420ms/step - loss: 0.9723 - acc: 0.9116 - val_loss: 1.1073 - val_acc: 0.8284\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 5s 423ms/step - loss: 0.9833 - acc: 0.8764 - val_loss: 1.1052 - val_acc: 0.8333\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 0.9971 - acc: 0.8806 - val_loss: 1.1054 - val_acc: 0.8382\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 5s 424ms/step - loss: 0.9794 - acc: 0.8924 - val_loss: 1.1056 - val_acc: 0.8382\n",
      "Epoch 85/200\n",
      "11/12 [==========================>...] - ETA: 0s - loss: 0.9840 - acc: 0.8905"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3966d33d8a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_test_arr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                         callbacks=[lr_reducer])\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2201\u001b[0m                                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                                 verbose=0)\n\u001b[0m\u001b[1;32m   2204\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1742\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1380\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_augmentation = True\n",
    "trainGene = trainGenerator(x_train_arr,f_train_arr,y_train_arr)\n",
    "testGene = testGenerator(x_test_arr,f_test_arr,y_test_arr)\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit([x_train_arr, f_train_arr], y_train_arr,\n",
    "             batch_size = batch_size,\n",
    "             nb_epoch = nb_epoch,\n",
    "             validation_data = ([x_test_arr, f_test_arr], y_test_arr),\n",
    "             shuffle = True,\n",
    "             callbacks = [lr_reducer, csv_logger])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    model.fit_generator(trainGene,\n",
    "                        steps_per_epoch=x_train_arr.shape[0] // batch_size,\n",
    "                        validation_data=([x_test_arr, f_test_arr], y_test_arr),validation_steps = x_test_arr.shape[0]//batch_size,\n",
    "                        epochs=nb_epoch, verbose=1, max_q_size=100,\n",
    "                        callbacks=[lr_reducer])\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 2\n",
    "nb_epoch = 200\n",
    "Mysgd = keras.optimizers.SGD(lr=0.01)\n",
    "MyAdam = keras.optimizers.Adam(lr=0.1)\n",
    "\n",
    "model = resnet.ResnetBuilder.build_resnet_50((1, 128, 128), nb_classes)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = True\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit([x_train_arr, f_train_arr], y_train_arr,\n",
    "             batch_size = batch_size,\n",
    "             nb_epoch = nb_epoch,\n",
    "             validation_data = ([x_test_arr, f_test_arr], y_test_arr),\n",
    "             shuffle = True,\n",
    "             callbacks = [lr_reducer, csv_logger])\n",
    "else:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train_arr)\n",
    "    \n",
    "    print('Using real-time data augmentation.')\n",
    "    model.fit_generator(datagen.flow(x_train_arr, y_train_arr, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train_arr.shape[0] // batch_size,\n",
    "                        validation_data=(x_test_arr, y_test_arr),validation_steps = x_test_arr.shape[0]//batch_size,\n",
    "                        epochs=nb_epoch, verbose=1, max_q_size=100,\n",
    "                        callbacks=[lr_reducer])\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 2\n",
    "nb_epoch = 200\n",
    "Mysgd = keras.optimizers.SGD(lr=0.01)\n",
    "MyAdam = keras.optimizers.Adam(lr=0.1)\n",
    "\n",
    "model = MyNetWork.NetBuilder.ST_res50(input_shape = (128, 128, 1), num_outputs = nb_classes, sampling_size = (128, 128))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = True\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit([x_train_arr, f_train_arr], y_train_arr,\n",
    "             batch_size = batch_size,\n",
    "             nb_epoch = nb_epoch,\n",
    "             validation_data = ([x_test_arr, f_test_arr], y_test_arr),\n",
    "             shuffle = True,\n",
    "             callbacks = [lr_reducer, csv_logger])\n",
    "else:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train_arr)\n",
    "    \n",
    "    print('Using real-time data augmentation.')\n",
    "    model.fit_generator(datagen.flow(x_train_arr, y_train_arr, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train_arr.shape[0] // batch_size,\n",
    "                        validation_data=(x_test_arr, y_test_arr),validation_steps = x_test_arr.shape[0]//batch_size,\n",
    "                        epochs=nb_epoch, verbose=1, max_q_size=100,\n",
    "                        callbacks=[lr_reducer])\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
