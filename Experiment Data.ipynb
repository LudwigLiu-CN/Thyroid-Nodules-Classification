{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import resnet\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage import feature as ft\n",
    "from skimage import transform\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "import FinalNetwork \n",
    "import MyNetWork \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureselected(img):\n",
    "    hog_features = ft.hog(img,  # input image\n",
    "                  orientations=8,  # number of bins\n",
    "                  pixels_per_cell=(20,20), # pixel per cell\n",
    "                  cells_per_block=(2,2), # cells per blcok\n",
    "                  block_norm = 'L2-Hys', #  block norm : str {‘L1’, ‘L1-sqrt’, ‘L2’, ‘L2-Hys’}\n",
    "                  transform_sqrt = True, # power law compression (also known as gamma correction)\n",
    "                  feature_vector=True, # flatten the final vectors\n",
    "                  visualize=False) # return HOG map\n",
    "    \n",
    "    temp = img.reshape(128,128)\n",
    "    \n",
    "    lbp_features = ft.local_binary_pattern(temp,  # input image\n",
    "                                   P=8,  # Number of circularly symmetric neighbour set points\n",
    "                                   R=1.0, # Radius of circle\n",
    "                                   method='default') # {'default', 'ror', 'uniform', 'var'}\n",
    "    \n",
    "    haar_features = ft.haar_like_feature(temp,  # input image\n",
    "                                0,  # Row-coordinate of top left corner of the detection window.\n",
    "                                0,  # Column-coordinate of top left corner of the detection window.\n",
    "                                5,  # Width of the detection window.\n",
    "                                5,  # Height of the detection window.\n",
    "                                feature_type=None # The type of feature to consider:\n",
    "                                )\n",
    "    \n",
    "    _lbp = lbp_features.flatten()\n",
    "    \n",
    "    train = np.concatenate((hog_features, _lbp, haar_features),axis=0)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(x_train_arr,f_train_arr,y_train_arr):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "    \n",
    "    \n",
    "    genX1 = datagen.flow(x_train_arr,y_train_arr, batch_size=batch_size)\n",
    "#    genX2 = datagen.flow(f_train_arr, batch_size=batch_size)\n",
    "#     while True:\n",
    "#         X1i = genX1.next()\n",
    "#         X2i = genX2 .next()\n",
    "#         print (X1i[0].shape)\n",
    "#         print (X2i.shape)\n",
    "#         print (X1i[1].shape)\n",
    "#         yield ([X1i[0], X2i ], X1i[1])\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        #X2i = genX2 .next()\n",
    "        features = []\n",
    "        for i in range(len(X1i[0])):\n",
    "            features.append(featureselected(X1i[0][i]).reshape(1, 17472, 1))\n",
    "        features = np.array(features)\n",
    "\n",
    "        yield ([X1i[0], features ], X1i[1])   \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "def testGenerator(x_test_arr,f_test_arr,y_test_arr):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    datagen = ImageDataGenerator(rotation_range=90, \n",
    "                                   width_shift_range=0.05, \n",
    "                                   height_shift_range=0.05,\n",
    "                                   zoom_range=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    genX1 = datagen.flow(x_test_arr,y_test_arr, seed=7, batch_size=batch_size)\n",
    "    genX2 = datagen.flow(f_test_arr, seed=7, batch_size=batch_size)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "\n",
    "        yield ([X1i[0], X2i ], X1i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incorrect_index(predicts, real_labels):\n",
    "    results = np.empty(0)\n",
    "    for i in range(predicts.shape[0]):\n",
    "        if real_labels[i][0] == 1:\n",
    "            if predicts[i][0] < 0.3:\n",
    "                results = np.append(results, i)\n",
    "        else:\n",
    "            if predicts[i][1] < 0.3:\n",
    "                results = np.append(results, i)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def delete_index(incorret_lists):\n",
    "    counts = np.zeros(206, dtype=int)\n",
    "    for invalid in incorrect_lists:\n",
    "        for i in invalid:\n",
    "            counts[int(i)] += 1\n",
    "    \n",
    "    results = np.empty(0)\n",
    "    for i in range(206):\n",
    "        if counts[i] >= 5:\n",
    "            results = np.append(results, i)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 17472)\n",
      "(1022, 128, 128, 1)\n",
      "(1022, 2)\n",
      "(1022, 1, 17472, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "Input = np.load('Data/final_data.npz')\n",
    "\n",
    "data = Input[\"data\"]\n",
    "label = Input[\"label\"]\n",
    "\n",
    "feature = []\n",
    "for i in range(data.shape[0]):\n",
    "    feature.append(featureselected(data[i]))\n",
    "feature = np.array(feature)\n",
    "print (feature.shape)\n",
    "feature.resize(feature.shape[0],1, feature.shape[1],1)\n",
    "\n",
    "print (data.shape)\n",
    "print (label.shape)\n",
    "print (feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 1, 17472, 1)\n"
     ]
    }
   ],
   "source": [
    "def unison_shuffled_copies(a, b, c, rl):\n",
    "    assert len(a) == len(b)\n",
    "    assert len(a) == len(c)\n",
    "    r=list(range(len(a)))\n",
    "#     random.shuffle(r,lambda:rl)\n",
    "    random.shuffle(r,lambda:rl)\n",
    "    p=np.array(r)\n",
    "    #p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p]\n",
    "\n",
    "data,label,feature=unison_shuffled_copies(data,label,feature,0.5)\n",
    "\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------0--------------------------------------------------\n",
      "(204, 128, 128, 1)\n",
      "-------------------------------------------1--------------------------------------------------\n",
      "(204, 128, 128, 1)\n",
      "-------------------------------------------2--------------------------------------------------\n",
      "(204, 128, 128, 1)\n",
      "-------------------------------------------3--------------------------------------------------\n",
      "(204, 128, 128, 1)\n",
      "-------------------------------------------4--------------------------------------------------\n",
      "(206, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    print('-------------------------------------------'+str(i)+'--------------------------------------------------')\n",
    "    splitpoint1 = int(i * 204)\n",
    "    splitpoint2 = int((i + 1) * 204)\n",
    "    if(i==4):\n",
    "        splitpoint2 = data.shape[0]\n",
    "    train_x = np.vstack((data[:splitpoint1], data[splitpoint2:]))\n",
    "    train_f = np.vstack((feature[:splitpoint1], feature[splitpoint2:]))\n",
    "    train_y = np.vstack((label[:splitpoint1], label[splitpoint2:]))\n",
    "    val_x = data[splitpoint1:splitpoint2]\n",
    "    val_f = feature[splitpoint1:splitpoint2]\n",
    "    val_y = label[splitpoint1:splitpoint2]\n",
    "    incorrect_list=[]\n",
    "    print(val_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------0--------------------------------------------------\n",
      "(204, 128, 128, 1)\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilab/.conda/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:49: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., verbose=0, validation_data=([array([[..., steps_per_epoch=102, epochs=150, callbacks=[<keras.ca..., max_queue_size=100, validation_steps=25)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test score:', 7.861898702733657)\n",
      "('Test accuracy:', 0.5147058826451208)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6230512156206018)\n",
      "('Test accuracy:', 0.7156862733410854)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.588016459754869)\n",
      "('Test accuracy:', 0.7254901949097129)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6702137250526279)\n",
      "('Test accuracy:', 0.6225490184391246)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6909128696310753)\n",
      "('Test accuracy:', 0.6225490196078431)\n",
      "('delete count:', 5)\n",
      "-------------------------------------------1--------------------------------------------------\n",
      "(204, 128, 128, 1)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6913022784625783)\n",
      "('Test accuracy:', 0.651960785482444)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6751316587130228)\n",
      "('Test accuracy:', 0.7009803921568627)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6180680475982965)\n",
      "('Test accuracy:', 0.7254901960784313)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.7660485587868036)\n",
      "('Test accuracy:', 0.6225490207765617)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6223391972336114)\n",
      "('Test accuracy:', 0.6666666654979482)\n",
      "('delete count:', 3)\n",
      "-------------------------------------------2--------------------------------------------------\n",
      "(204, 128, 128, 1)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6326540965659946)\n",
      "('Test accuracy:', 0.7009803933255813)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6271265675039852)\n",
      "('Test accuracy:', 0.6862745109726401)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6392128268877665)\n",
      "('Test accuracy:', 0.6666666678353852)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6042143468763314)\n",
      "('Test accuracy:', 0.6960784325412676)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6514224608739217)\n",
      "('Test accuracy:', 0.6764705894040126)\n",
      "('delete count:', 9)\n",
      "-------------------------------------------3--------------------------------------------------\n",
      "(204, 128, 128, 1)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.5941782336609036)\n",
      "('Test accuracy:', 0.6862745098039216)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6244245288418788)\n",
      "('Test accuracy:', 0.7303921568627451)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6619648781477236)\n",
      "('Test accuracy:', 0.6911764694195167)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6062566310751671)\n",
      "('Test accuracy:', 0.7058823529411765)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.590010891942417)\n",
      "('Test accuracy:', 0.7156862745098039)\n",
      "('delete count:', 4)\n",
      "-------------------------------------------4--------------------------------------------------\n",
      "(206, 128, 128, 1)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6603843390362935)\n",
      "('Test accuracy:', 0.6844660205748475)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6027490676028057)\n",
      "('Test accuracy:', 0.6893203900855722)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.7358634622351637)\n",
      "('Test accuracy:', 0.6650485454253781)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6599241859704545)\n",
      "('Test accuracy:', 0.6456310696972226)\n",
      "Using real-time data augmentation.\n",
      "('Test score:', 0.6307443322487247)\n",
      "('Test accuracy:', 0.6699029143574169)\n",
      "('delete count:', 4)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "nb_classes = 2\n",
    "nb_epoch = 150\n",
    "data_augmentation = True\n",
    "deleteIndexes = np.zeros(0)\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('-------------------------------------------'+str(i)+'--------------------------------------------------')\n",
    "    splitpoint1 = int(i * 204)\n",
    "    splitpoint2 = int((i + 1) * 204)\n",
    "    if(i==4):\n",
    "        splitpoint2 = data.shape[0]\n",
    "    train_x = np.vstack((data[:splitpoint1], data[splitpoint2:]))\n",
    "    train_f = np.vstack((feature[:splitpoint1], feature[splitpoint2:]))\n",
    "    train_y = np.vstack((label[:splitpoint1], label[splitpoint2:]))\n",
    "    val_x = data[splitpoint1:splitpoint2]\n",
    "    val_f = feature[splitpoint1:splitpoint2]\n",
    "    val_y = label[splitpoint1:splitpoint2]\n",
    "    incorrect_lists=[]\n",
    "    print(val_x.shape)\n",
    "    \n",
    "    for j in range(5):\n",
    "        K.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "    \n",
    "        lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "        #csv_logger = CSVLogger('RoomsLogger/Room' + str(i)+'_'+str(j) + '.csv')\n",
    "        early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
    "        #checkpoint = ModelCheckpoint('RoomModel/Model_'+str(i)+'_'+str(j)+'.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "        model =  FinalNetwork.NetBuilder.finalNet(input_shape = (128, 128, 1), feature_shape = (1,17472, 1), num_outputs = nb_classes, sampling_size = (128, 128))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "        trainGene = trainGenerator(train_x,train_f,train_y)\n",
    "\n",
    "        if not data_augmentation:\n",
    "            print('Not using data augmentation.')\n",
    "        \n",
    "        else:\n",
    "            print('Using real-time data augmentation.')\n",
    "            model.fit_generator(trainGene,\n",
    "                                steps_per_epoch=train_x.shape[0] // batch_size,\n",
    "                                validation_data=([val_x, val_f], val_y),validation_steps = val_x.shape[0]//batch_size,\n",
    "                                epochs=nb_epoch, verbose=0, max_q_size=100,\n",
    "                                callbacks=[lr_reducer, early_stopper])\n",
    "        \n",
    "        score = model.evaluate([val_x, val_f], val_y, verbose=0)\n",
    "        print('Test score:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "    \n",
    "        predictions = model.predict([val_x, val_f], verbose=0)\n",
    "    \n",
    "        incrt = incorrect_index(predictions, val_y)\n",
    "        incorrect_lists.append(incrt)\n",
    "        \n",
    "    useless_index = delete_index(incorrect_lists)\n",
    "    print(\"delete count:\", useless_index.shape[0])\n",
    "    deleteIndexes = np.append(deleteIndexes, 204*i+useless_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  46.   50.   59.   72.  193.  258.  275.  361.  416.  439.  468.  504.\n",
      "  519.  561.  572.  575.  610.  676.  689.  694.  767.  848.  872.  967.\n",
      " 1003.]\n"
     ]
    }
   ],
   "source": [
    "print(deleteIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(997, 128, 128, 1)\n",
      "(997, 2)\n"
     ]
    }
   ],
   "source": [
    "selected_data = []\n",
    "selected_label = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    if np.isin(i, deleteIndexes, invert=True):\n",
    "        selected_data.append(data[i])\n",
    "        selected_label.append(label[i])\n",
    "        \n",
    "selected_data = np.array(selected_data)\n",
    "selected_label = np.array(selected_label)\n",
    "        \n",
    "print(selected_data.shape)\n",
    "print(selected_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Data/experimentData.npz', data=np.array(selected_data), label=np.array(selected_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Input = np.load('Data/experimentData.npz')\n",
    "\n",
    "data = Input[\"data\"]\n",
    "label = Input[\"label\"]\n",
    "\n",
    "num_0 = 0\n",
    "for i in label:\n",
    "    if i[0]==1:\n",
    "        num_0+=1\n",
    "        \n",
    "print(num_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
